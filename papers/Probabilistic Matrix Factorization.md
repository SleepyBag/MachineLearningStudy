# Probabilistic Matrix Factorization
---

## PMF方法

PMF实质上是SVD方法的另一种阐述方式。

* SVD的思路是通过最小化最小二乘误差来实现UV对R的拟合。
* PMF的思路是通过极大似然估计来求得在几个超参数（U，V与R的方差）的先验条件下U与V的最大可能的取值。
* PMF的超参数与SVD的正则化参数效果是一样的，式子也是完全一样的。但是PMF中正则化参数有了更清楚的意义。

## 超参数学习

因为在PMF中超参数有了明确的意义，所以可以通过假设其超参数的先验的方式来将超参数加入到可优化参数当中（虽然通常还是假设为高斯分布这个万能的分布）。
在假设高斯分布的前提下，如果U和V固定，那么此时最优方差可以直接求得闭式解。因此优化过程中可以使用“求解最优方差”与“梯度下降求U与V”交替进行的方式。

## 受限PMF

本文的主要创新点。新增了一个矩阵W来表示“看过某电影的用户的特征”（不考虑评分值）来提升模型对不活跃用户的推荐性能。

<img src="http://chart.googleapis.com/chart?cht=tx&chl=U_i=Y_i%2B(\sum_kI_{ik}W_k)/(\sum_kI_{ik}) " style="border:none;">

还没有开始学LaTex，公式有点难看。I矩阵代表用户看过一个电影与否，看过为1，没看过为0。加号后面的项为“看过某电影的用户群体的兴趣状态”，加号前面的项为根据评分求得的兴趣状态。这样设置可以让看过相同电影（不一定评分相同）的用户拥有近似的状态。

>*我的理解：在朴素PMF中，I为0，即用户没有评过的电影被视为缺失数据，没有加以利用。而在受限PMF中，“有没有评分”这一属性本身被视为了一项数据，被用来作为聚类依据。因此对于评分较少的用户，受限PMF可以获得更好的结果。*

如此求出U矩阵，替代朴素PMF的目标函数中的U矩阵，即可对W进行优化。
受限PMF在一个用户评分过的电影较少的情况下可以根据他看过的电影得出较好的结果。

## 收获

* 最小二乘法本身可以从参数估计的角度解释，通过从参数估计的角度分析，可以获知正则化参数的真实意义
* 评分数据可以从数值的大小角度来建模，也可以根据“有”或者“没有”来建模
